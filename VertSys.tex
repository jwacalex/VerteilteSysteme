\documentclass[pagesize,11pt,a4paper]{scrartcl}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}


%todo: intern/extern synchro erklären
\begin{document}
\paragraph*{Verteiltes System}
	Ansammlung unabhängiger Computer, die wie ein einzelnes System erscheinen; 
	Menge interagierender Prozesse, über Nachrichten kommunizierend;

\paragraph*{Ziele für Verteilte Systeme}
	Gemeinsame Ressourcennutzung;
	Transparenz (Zugriff, Ort, Migration, Relokation, Replikation, Nebenläufigkeit, Fehler);
	Offenheit (Spezifiziert u. Vollständigkeit der Schnittstellen. Folge: Interoperabel, Portabel) (sei konservativ in dem, was Du sendest, sei tolerant in dem, was Du empfängst);
	Skalierbarkeit (Bottleneck, Single Point of Failure, etc) (durch Async, Aufteilung, etc);
	
\paragraph*{Cloud}
	Abstraktion: logische / physikalische Transparenz; 

\paragraph*{Architekturen}
	Geschichtet:ISO/OSI, Multi-Tier, Drei-Tier (Dispatch-Worker), Middleware;
	Ereignisbasiert: Push/Subscribe
	Objektbasiert: RMI/RPC;
	Zentral: Client/Server;
	Dezentral: Overlay: Mutlicast auf Anwendungsbene, P2P (Superpeer-Konzept);
	Hybridformen
	
\paragraph*{Prozess vs Thread}
	Thread: leichtgewichter Prozess mit geteiltem Speicherbereich;
	LWP: Vergleiche mit Worker in Java;

\paragraph*{Mutex}
	Lösung: Semaphoren, Monitore, Locks, Warten (Aktiv, Passiv);
	Erkennung von Deadlocks: Timeout, Wait-For-Graph;
	Unterschied Semaphore - Monitor: Monitor schon zur Kompilezeit (Sperrt bei Ausführung Monitorraum)
	Konkurierender Zugriff (Deadlock, Starvation);
	Lösungen: 
		Tokenbasierte (Probleme: Tokenverlust, nur ein Token), 
		Koordinator (Loadbalanic, etc, aber single point of failure, bottleneck),
		Dezentrale Koordinatoren: Zugriff nach Votum (Problem: Effizienz, garkein Votum bei sehr vielen Anfragen)
		verteilt (Ricard und Agrawala): (Jeder Prozess Kordiniert, Problem: ein Prozess stürzt ab)  
 		Kordinatorbestimmung: 
			Bully - Wahlnachricht an Prozesse höhere Nummern|Wenn kein Prozess antwortet, übernimmt Prozess| ansonsten rekursiv weiter,
			Ring: Nachfolger Übernimmt/wird bestimmt (oder nächster) (Nachricht wird einmal rumgereicht)

\paragraph*{ACID}
	Transaktionskonsitenz:
		Atomic Consistent Isolation Durability;
	Transaktionsmonitor überwacht

\paragraph*{ISO-Modell}
	Physical, Data, Network, Transport, Session, Presentation, Application
	
\paragraph*{Stubs}
	Stumpf (Anknüpfungspunkt);
	Client-Stub: ersetzt lokalen Prozeduraufruf;
	Parameter an Server, warten, etc;
	Server-Stub: Operation, Datenverarbeiten;

\paragraph*{RPC}
	sync. Kontrollfluss/Datenuebergabe, Prozeduraufruf, unterschiedliche Adressräume, schmaler Kanal;
	parallelität durch asynch;
	Call by Value -> Marshalling der Parameter
	Call By Reference -> Verbot von Zeigern und Verweisten  (Kopie);
	
\paragraph*{Berkeley Sockets}
	Schnittstelle f. nachrichtenorientierte, fluechtige Kommunikation

\paragraph*{MPI}
	:)

\paragraph*{Marshalling}
	Umwandeln von strukturieren Daten in Übertragungsformat
	
\paragraph*{Serialisierung}
	Sturkturierte Daten in sequenzielles Format (Speicherung, implementation von Marshalling)
	
\paragraph*{Kommunikation}
	persistent: Speicherung in Mittleware bis Zustellung;
	transient (flüchtig): Anwendungsausführungszeit

\paragraph*{Chord}
	Entität mit Schlüssel k -> Konten mit Bezeichner id >= k (bzw. k <= id). Nachfolger von k;
	Suche: Knoten betrachtet Vogänger und Nachfolger, wenn Vorgängern < k < Konten -> Knoten zuständig, sonst weiterleitung;
	Bei Fingertabelle: Ordne Schlüssel bei einträgen ein Eintrag i < k < Eintrag i+1 => Weiterleitung Eintrag 1 -> Sonst k an Knoten;
	Hinzukommen/Verlassen: Einfach in Ring einbauen; Aktualisierung der Fingertabellen: Prüfen ob man Vorgänger des Nachfolgers ist ->
		Falls ja: alles ok -
		Fall nein: neuer Knoten -> Knoten < neuer Knoten <= Nachfolger d. Knotens. Anpassung der ersten Position der Fingertabelle. Für jeden weiteren Eintrag, analog. im Nachfolger ebenfalls durch den Vorgänger-

\paragraph*{Cristians Algo}
	externe Synchro;
	Neue Zeit: Serverzeit + RTT /2  Genauigkeit: +-(RTT/2 - minÜbertragungszeit);
	(Setzen der Uhr auf: Server gemeldete Zeit + RTT/2);
	NIEMALS RÜCKLAUFEN DER UHR;
	Probleme: Server fällt aus, Server sendet falsch, Probleme im Netz;

\paragraph*{NTP}
	Implementiert Cristian, bei der die Bearbeitungszeit der Anfrage raus gerechnet wird;
	T1: Absenden, T2: Eintreffen Zeitserver, T3: Absenden Antwort Zeitserver; T4: Eintreffen Rechner;
	T2 -T1: Laufzeit Anfrage; T4-T3: Laufzeit Antwort;
	Laufzeit in eine Richtung -> Mittel aus beiden Anfragen;
	Abweichung der Uhr Aufaddieren: ((T2-T1)+(T3-T4)) / 2;
	Uhr weiss wie gut sie ist;
	Berechnungen (8x) von Laufzeit und Abweichung. Verwendung dieses Wertepaars;
	Gleiches Stratum -> Abgleich, ansonsten nur größerer Stratum update;
	Synchronisationsmodi: Multicast (Server schickt periodisch aktuelle Zeit per Multicast, geringe Genaugigkeit), Procedure-Call-Modus: Ähnlich Cristian Algorigmus (Mittlere Genauigkeit), Symmetrischer Modus: Wechselseitiger Austausch von Zeitstempeln (hohe Genauigkeit); 

\paragraph*{Berkely}
	interne Synchro;
	Aktiver Zeitserver; Fragt Systeme an; Bilden Durschnittszeit; Angleichen;
	Nur möglich wenn gemeinsame Zeit innerhalb System notwendig;
	Zur Fehlervermeidung: Nur Mittelwert aus Uhren mit best. Abweichung;

\paragraph*{In Drahtlosen Systeme}
	Kommunkation teuer; Reference Broadcast (RBS);

\paragraph*{Logische Uhren}
	Keine Notwendigkeit bei bei fehlender Wechselwirkung, Nur Ereignisreihenfolge wichtig;
	Happens-Before-Relation: Alle Prozesse stimmen ein, dass A vor B stattfand.
		Beispiel: A und B nacheinander im gleichen Prozess -
		oder A sendet Nachricht, B empfängt diese Nachricht -> A vor B;
	sind transitiv, Zeitwerte von A ist kleiner als von B;
	Uhr geht immer vorwärts (Nur Addition)

\paragraph*{Lamportuhr}
	Vor Ereignis: Erhöhen des Zählers;
	Bei Transaktion: Zeitstempel (Zähler mitsenden);
	Bei Empfang: höheren Wert aus (lokalem Zähler und Zeitstempel) nehmen Danach Zähler erhöhen;
	Keine zwei Ereignisse mit gleicher Zeit.
	LC1: Li wird vor Behandlung eines Events (Senden) in Prozess pi erhöht;
	LC2: Versand: Setzen des Timestamps pi, b) nach empfang in pj timestamp auf max+1 setzen (entweder TS von Pi, oder pj)

\paragraph*{Vectorclock}
	Wie Lamportuhr, jedoch Zähler für jeden Prozess;
	VC1: Anfangs VCi = 0 für jedes i,j;
	VC2: Vor einem Event (Senden) TS von sich erhöhen;
	VC3: Bei Empfang: Zusammenführung der Timestamps (jeweils max)
\paragraph*{Globaler Zustand}
	Alle lokalen Zustände der Prozesse und alle Nachrichten in der Übertragung;
	Gesamtzustand ist nicht exakt zu bestimmen, da keine Sync. via Uhr möglich;


\paragraph*{Lamport vs. Vector Clock}
	Laport: a -> b, d.h. LaportClock von a < LamportClock b, ABER L(a) < L(b) gilt nicht a -> b, Aber: L(a) >= L(b) d.h. a nicht vor b;
	Vector: a->b gdw. V(a) < V(b)



\paragraph*{History}
	Local History: alle Nachrichten eines Prozesses;
	Global History: alle Nachrichten aller Prozesse;
	
\paragraph*{Cut}
	Teilmenge der Global History;
	Frontier des Cuts: die Menge der jeweils letzten Events der Prozesse;
	Consistent Cut: wenn für alle im Cut enthaltene Events auch ihre Vorgänger enthalten ist;
	Run: die totale Ordnung in der Global Histroy (konsistent bezüglich Local History);

\paragraph*{Replikation}
	Caching, Datenverteilung/Duplizierung
	Plazierung der Server: gleichmäßig (z.B. Minimaler Abstand im Graph).
	Verwaltung: Aktualisierungsbenachrichtigung Weiterleiten, Push/Pullansatz

\paragraph*{Konsistenz}
	Wichtig: Vermeindung von Konsistenzproblemen;
	stufenlos: Conit (kleinste konsistente Einheit (Quasiatomar));
	sequenztiell: Paralleler Datenzugriff (kein falsches lesen);
	kausal: Schreibvorgänge in Kausaler Beziehung (Lesen vor Schreiben, keine Konflikte)
	eventual consistency: schwache Konsistenz, Replikate nach und nach aktualisieren;
	monotones Lesen: wenn prozess datensatz liesst -> immer x oder aktuelleren Zurückgeben;
	read your writes: schreiboperation wird immer vor leseoperation abgeschlossen;
	write follows read: wenn nach lesen geschrieben wird, hat operation aktuellen oder selben wert f. x

\paragraph*{Operationsgruppierungen}
	Kritische Bereiche;

\paragraph*{Byte-Reihenfolge}
	Big-Endian: Höchstwertiges Bit zuerst (kleinste Speicherstelle);
	Little-Endian: LSB an kleiner;
	Network-Byte-Order: Byte-Reihenfolge beim Netzwerkübertragen;
	Host-Byte-Order: Byte Reihenfolge auf dem System;

\paragraph*{Streams}
	(a)synchron oder isochron (beschränkert Jitter);
	Dienstgüte (QoS): min Bitrate, max Verzögerung, max End2End verzögerung; max Jitter, etc;
	Fix auf Anwendungsebne: Puffer, vorwärsgerichtete Fehlerkorrektur;
	Synchronisation: auf Datenebene, Steuerungsschnittstelle

\paragraph*{Broad/Multicast}
	Kommunikation zu Gruppe von Empfängern - Ebene: Network/Transporation-Layer;
	Probleme: Sturktur des Overlay wenig mit Netzstruktur unterliegender Schichten, analog f. Routing;
	Können zum auffinden von Entitäten verwendet werden;

\paragraph*{Namen, etc}
	Bezeichner: Für immer Eindeutig;
	Adresse, Name, FQDN: änderbar;

\paragraph*{Lineare Benennung}
	Bezeichner aus zufälliger Bitfolge -> Keine Information über Lokalisation

\paragraph*{Lokalisierung}
	Zeiger: Bei Ortswechsel -> Hinweis auf nächsten Ort etc (Nachteil: Lange Kette, Problem bei gebrochener Kette) [Alternative: Homezone];
	Alternative DHT, etc (Chord);
	Hierarchische Systeme: Namensgraph von Startknoten aus (UnixFS, DNS);

\paragraph*{Namensauflösung}
	Closure-Mechanismus - Wichtig ist das Wissen WIE aufgelöst wird;
	Alias: Gleiche Entität, anderer Name (z.B. Symbolischer Link);

\paragraph*{Benennung}
	AttributbasierendJede Entität hat mehrere Attribute) -> Verzeichnisdienst oder via RDF;
	Hierarchisch: LDAP (Problem: Bei Such nach Attribut, Laufzeit von O($nixGut$));
	Alternative.: Dezentrale attributbasierende Namenssysteme: DHT, Darstellung als Baum;

\paragraph*{Uhren}
	Physiaklische Uhren: Hardware (Quarz, Registermagie) -> Dirft (Thermisch) - Abweichung zwischen Uhren Skew;

\paragraph*{GPS}
	Funktion: Triangulation (Zeit, Ausbreitungsgeschwindigkeit);
	Probleme: Ungenaue Referenzkoordinaten, Multipfadausbreitung, Ionospährische/etc Verzögerungen, Uhrsync, Geometrie, Postionsmeldung;
	
\paragraph*{Verteilung}
	Horizontal: Sichten/Tiers mit versch. Zuständigkeiten
	Flach/P2P: jeder Client ist identisch.

\paragraph*{Programmiersprachen (C)}
	Syntax: Grammatische Struktur, Sematik Bedeutung;
	Pointer: Zeigt auf Adresse (typ *) - Dereferenzierung (wieder Inhalt) *, Speicherzelle(\&);
	Struct: Mehrere Typen im Speichebereich zusammengefasst, Zugriff: struct.feld, via pointer struct->feld o. (*struct).feld;
	array: pointer auf startadresse. viel synaktischer zucker (p[100] = *(p + 100) = *(100 + p) = 100[p]), bei OutOfBounds -> SegFault;

\subparagraph*{Bubblesort in C}
	*a \^= *b ; *b \^= *a ; *a \^= *b;:;
	Algo wie aus A\&D

\paragraph*{Middleware}
	Schicht zwischen Anwendungen;
	Ziel: Verteilungstransparenz;
	Kosten: Mehraufwand f. Steuerung;

\paragraph*{TCP vs. UDP}
	TCP: Verbindungsorientiert, Fluss/Übertragungssteuerung, Segmentierung, Retransmission, Verlustfreiheit;
	UDP: Paketbasiert, KEINERLEI Fluss/Übertragungssteuerung;
	
\paragraph*{Happend-Before-Relation}
	HB1: (lokale Ordnung gilt auch global) $\exists$ Prozess pi: e -> e', dann e-> e';
	HB2: Für jede Nachricht m, send(m) -> recive(m), wobei send/recive(m) das Event der Nachricht ist (send vor recive);
	HB3: Transitivität: e,e2,e3: e->e2, e2->3, d.h. e->e2;

\paragrah*{(Global) History}
	Art Linearisierung der Prozesse in Reihenfolge einer ggf happen-before-relation;
	Run: totale Ordnung einer globalen History, die Konsisten zg. jeder Ordnung der lokalen History;
	Lineraization (Consistent Run): Ordnung von Events in einer Global History, bezüglich Happend-Before konsistent;
	Run vs. Consistent State: Nicht alle Runs durchlaufen Consistent Global States, jedoch alle Linearizations nur Consistent Global States;

\paragraph*{Cut}
	Teilmenge der Global History;
	Frontier: Zustand der Events direkt nach dem Cut;
	Consistent Cut: Cut, der keine Happen-Before-Relation verletzt (kein Empfang ohne Absender)
	Consistent Global State: Globaler Zustand entpsircht Endzustand nach Consitent Cut
	

\end{document}